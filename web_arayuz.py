import streamlit as st
import pandas as pd
import torch
import matplotlib.pyplot as plt
import seaborn as sns
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
import pickle
import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import joblib
import os

# NLTK'nin gerekli verileri indirme iÅŸlemini gerÃ§ekleÅŸtirir
try:
    nltk.data.find('tokenizers/punkt')
    nltk.data.find('corpora/stopwords')
    # AyrÄ±ca punkt_tab'Ä± kontrol eder
    nltk.data.find('tokenizers/punkt_tab')
except LookupError:
    print("NLTK veri paketleri indiriliyor...")
    nltk.download('punkt')
    nltk.download('stopwords')
    try:
        nltk.download('punkt_tab')
    except:
        # EÄŸer paket bulunamazsa, Ã¶zel indirme iÅŸlemi uygular
        print("punkt_tab iÃ§in alternatif Ã§Ã¶zÃ¼m uygulanÄ±yor...")
        # Tokenizer'Ä± direkt olarak word_tokenize'Ä± kullanacak ÅŸekilde deÄŸiÅŸtirir
    print("Ä°ndirme tamamlandÄ±.")
    
# TÃ¼rkÃ§e durak kelimelerini (stopwords) yÃ¼kler
try:
    tr_stop_words = set(stopwords.words('turkish'))
except LookupError:
    print("TÃ¼rkÃ§e stopwords indiriliyor...")
    nltk.download('stopwords')
    tr_stop_words = set(stopwords.words('turkish'))

# Ã–zel tokenize fonksiyonu (punkt_tab sorunu Ã§Ã¶zÃ¼mÃ¼ iÃ§in geliÅŸtirilmiÅŸtir)
def safe_tokenize(text):
    """GÃ¼venli tokenizasyon fonksiyonu, hata durumunda alternatif yÃ¶ntem kullanÄ±r"""
    if isinstance(text, str):
        try:
            return word_tokenize(text)
        except LookupError:
            # Basit tokenizasyon: boÅŸluklara gÃ¶re ayÄ±rma iÅŸlemi yapar
            return text.split()
    return []

# Sayfa baÅŸlÄ±ÄŸÄ±nÄ± ve genel yapÄ±landÄ±rmayÄ± ayarlar
st.set_page_config(page_title="Haber Kategori Tahmini", page_icon="ğŸ“°", layout="wide")
st.title("Haber Kategori Tahmini")
st.markdown("Bu uygulama, haber baÅŸlÄ±klarÄ±nÄ± kategorilerine gÃ¶re sÄ±nÄ±flandÄ±rÄ±r.")

# Metin temizleme iÅŸlemleri
def metin_temizle(text):
    """Metni temizleme: Ã¶zel karakterleri kaldÄ±rÄ±r ve kÃ¼Ã§Ã¼k harfe Ã§evirir"""
    if isinstance(text, str):
        # KÃ¼Ã§Ã¼k harfe Ã§evirme iÅŸlemi yapar
        text = text.lower()
        # Noktalama iÅŸaretlerini kaldÄ±rÄ±r
        text = re.sub(r'[^\w\s]', '', text)
        # Gereksiz boÅŸluklarÄ± kaldÄ±rÄ±r
        text = re.sub(r'\s+', ' ', text).strip()
        return text
    return ""

# Durak kelimeleri kaldÄ±rÄ±r
def durak_kelimeleri_kaldir(text):
    """TÃ¼rkÃ§e durak kelimelerini metinden Ã§Ä±karÄ±r ve temiz metin dÃ¶ndÃ¼rÃ¼r"""
    if isinstance(text, str):
        tokens = safe_tokenize(text)
        filtered_tokens = [word for word in tokens if word not in tr_stop_words]
        return ' '.join(filtered_tokens)
    return ""

# BERT iÃ§in metin temizler
def bert_metin_temizle(text):
    """BERT iÃ§in metni temizler: Ã¶zel karakterleri dÃ¼zenler ve gereksiz boÅŸluklarÄ± kaldÄ±rÄ±r"""
    if isinstance(text, str):
        # Gereksiz karakterleri kaldÄ±rÄ±r
        text = re.sub(r'[^\w\s.?!,]', '', text)
        # Gereksiz boÅŸluklarÄ± kaldÄ±rÄ±r
        text = re.sub(r'\s+', ' ', text).strip()
        return text
    return ""

# Modelleri yÃ¼kleme fonksiyonlarÄ±
@st.cache_resource
def load_tfidf_nb_model():
    """TF-IDF ve Naive Bayes modellerini yÃ¼kler ve hazÄ±r hale getirir"""
    try:
        # Model ve vektÃ¶rleÅŸtirici dosyalarÄ±nÄ± kontrol eder
        if os.path.exists('tfidf_vectorizer.pkl') and os.path.exists('nb_model.pkl'):
            with open('tfidf_vectorizer.pkl', 'rb') as f:
                tfidf_vectorizer = pickle.load(f)
            with open('nb_model.pkl', 'rb') as f:
                nb_model = pickle.load(f)
            return tfidf_vectorizer, nb_model
        else:
            st.warning("TF-IDF ve Naive Bayes model dosyalarÄ± bulunamadÄ±. Ã–nce modelleri eÄŸitmelisiniz.")
            return None, None
    except Exception as e:
        st.error(f"Model yÃ¼kleme hatasÄ±: {e}")
        return None, None

@st.cache_resource
def load_tfidf_lr_model():
    """TF-IDF ve Lojistik Regresyon modellerini yÃ¼kler ve kullanÄ±ma hazÄ±rlar"""
    try:
        # Model ve vektÃ¶rleÅŸtirici dosyalarÄ±nÄ± kontrol eder
        if os.path.exists('tfidf_vectorizer.pkl') and os.path.exists('lr_model.pkl'):
            with open('tfidf_vectorizer.pkl', 'rb') as f:
                tfidf_vectorizer = pickle.load(f)
            with open('lr_model.pkl', 'rb') as f:
                lr_model = pickle.load(f)
            return tfidf_vectorizer, lr_model
        else:
            st.warning("TF-IDF ve Lojistik Regresyon model dosyalarÄ± bulunamadÄ±. Ã–nce modelleri eÄŸitmelisiniz.")
            return None, None
    except Exception as e:
        st.error(f"Model yÃ¼kleme hatasÄ±: {e}")
        return None, None

@st.cache_resource
def load_bert_model():
    """BERT modelini yÃ¼kler ve tahmin iÃ§in hazÄ±r hale getirir"""
    try:
        # BERT model dosyasÄ±nÄ± kontrol eder
        if os.path.exists('bert_haber_siniflandirici.pth') and os.path.exists('model_siniflar.txt'):
            # SÄ±nÄ±flarÄ± dosyadan okur ve listeye dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r
            label_classes = []
            with open('model_siniflar.txt', 'r', encoding='utf-8') as f:
                for line in f:
                    parts = line.strip().split(': ')
                    if len(parts) == 2:
                        label_classes.append(parts[1])
            
            # GPU veya CPU cihazÄ±nÄ± belirler
            device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            
            # Tokenizer modelini yÃ¼kler
            tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-turkish-cased")
            
            # BERT sÄ±nÄ±flandÄ±rma modelini yÃ¼kler
            model = AutoModelForSequenceClassification.from_pretrained(
                "dbmdz/bert-base-turkish-cased",
                num_labels=len(label_classes)
            )
            
            # EÄŸitilmiÅŸ model aÄŸÄ±rlÄ±klarÄ±nÄ± yÃ¼kler ve cihaza taÅŸÄ±r
            model.load_state_dict(torch.load('bert_haber_siniflandirici.pth', map_location=device))
            model.to(device)
            model.eval()  # DeÄŸerlendirme moduna alÄ±r
            
            return tokenizer, model, label_classes, device
        else:
            st.warning("BERT model dosyalarÄ± bulunamadÄ±. Ã–nce modeli eÄŸitmelisiniz.")
            return None, None, None, None
    except Exception as e:
        st.error(f"BERT model yÃ¼kleme hatasÄ±: {e}")
        return None, None, None, None

# Tahmin fonksiyonlarÄ±
def predict_with_nb(text, vectorizer, model):
    """Naive Bayes ile metni sÄ±nÄ±flandÄ±rÄ±r ve sonuÃ§larÄ± dÃ¶ndÃ¼rÃ¼r"""
    if vectorizer is None or model is None:
        return "Model yÃ¼klenemedi. LÃ¼tfen Ã¶nce modeli eÄŸitin."
    
    # Metin Ã¶niÅŸleme adÄ±mlarÄ±nÄ± uygular
    clean_text = metin_temizle(text)
    processed_text = durak_kelimeleri_kaldir(clean_text)
    
    # TF-IDF ile vektÃ¶rleÅŸtirir ve tahmin yapar
    text_vector = vectorizer.transform([processed_text])
    prediction = model.predict(text_vector)[0]
    
    # OlasÄ±lÄ±klarÄ± hesaplayarak en yÃ¼ksek olasÄ±lÄ±ÄŸÄ± belirler
    probs = model.predict_proba(text_vector)[0]
    max_prob = max(probs) * 100
    
    return prediction, max_prob

def predict_with_lr(text, vectorizer, model):
    """Lojistik Regresyon ile metni sÄ±nÄ±flandÄ±rÄ±r ve sonuÃ§larÄ± dÃ¶ndÃ¼rÃ¼r"""
    if vectorizer is None or model is None:
        return "Model yÃ¼klenemedi. LÃ¼tfen Ã¶nce modeli eÄŸitin."
    
    # Metin Ã¶niÅŸleme adÄ±mlarÄ±nÄ± uygular
    clean_text = metin_temizle(text)
    processed_text = durak_kelimeleri_kaldir(clean_text)
    
    # TF-IDF ile vektÃ¶rleÅŸtirir ve tahmin yapar
    text_vector = vectorizer.transform([processed_text])
    prediction = model.predict(text_vector)[0]
    
    # OlasÄ±lÄ±klarÄ± hesaplayarak en yÃ¼ksek olasÄ±lÄ±ÄŸÄ± belirler
    probs = model.predict_proba(text_vector)[0]
    max_prob = max(probs) * 100
    
    return prediction, max_prob

def predict_with_bert(text, tokenizer, model, label_classes, device):
    """BERT ile derin Ã¶ÄŸrenme tabanlÄ± sÄ±nÄ±flandÄ±rma yapar ve sonuÃ§larÄ± dÃ¶ndÃ¼rÃ¼r"""
    if tokenizer is None or model is None or label_classes is None:
        return "BERT model yÃ¼klenemedi. LÃ¼tfen Ã¶nce modeli eÄŸitin."
    
    # BERT iÃ§in Ã¶zel metin temizleme iÅŸlemi uygular
    clean_text = bert_metin_temizle(text)
    
    # BERT tokenizer ile metni modelin anlayacaÄŸÄ± formata dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r
    encoding = tokenizer(
        clean_text,
        add_special_tokens=True,
        max_length=128,
        truncation=True,
        padding='max_length',
        return_tensors='pt'
    )
    
    # TensÃ¶rleri uygun cihaza (GPU/CPU) taÅŸÄ±r
    input_ids = encoding['input_ids'].to(device)
    attention_mask = encoding['attention_mask'].to(device)
    
    # Modeli kullanarak tahmin yapar
    with torch.no_grad():
        outputs = model(input_ids=input_ids, attention_mask=attention_mask)
        logits = outputs.logits
        probs = torch.nn.functional.softmax(logits, dim=1)
        max_prob, preds = torch.max(probs, dim=1)
    
    # Tahmin edilen sÄ±nÄ±fÄ± ve olasÄ±lÄ±ÄŸÄ± dÃ¶ndÃ¼rÃ¼r
    predicted_class = label_classes[preds.item()]
    probability = max_prob.item() * 100
    
    return predicted_class, probability

# ArayÃ¼z sekmelerini oluÅŸturur
tab1, tab2, tab3 = st.tabs(["Tahmin", "Veri Seti", "HakkÄ±nda"])

# Tahmin sekmesi iÃ§eriÄŸi
with tab1:
    st.header("Haber BaÅŸlÄ±ÄŸÄ± Tahmin Et")
    
    # KullanÄ±cÄ± giriÅŸi alanÄ±nÄ± oluÅŸturur
    user_input = st.text_area("Haber baÅŸlÄ±ÄŸÄ± girin:", height=100)
    
    # ÃœÃ§ modeli ayrÄ± sÃ¼tunlarda gÃ¶sterir
    col1, col2, col3 = st.columns(3)
    
    # Naive Bayes sÃ¼tunu
    with col1:
        if st.button("Naive Bayes ile Tahmin Et"):
            if user_input:
                # Naive Bayes modelini yÃ¼kler
                tfidf_vectorizer, nb_model = load_tfidf_nb_model()
                
                if tfidf_vectorizer is not None and nb_model is not None:
                    # Tahmin iÅŸlemini gerÃ§ekleÅŸtirir
                    prediction, probability = predict_with_nb(user_input, tfidf_vectorizer, nb_model)
                    
                    # SonuÃ§larÄ± kullanÄ±cÄ±ya gÃ¶sterir
                    st.success(f"Tahmin: **{prediction}**")
                    st.info(f"GÃ¼ven: {probability:.2f}%")
                else:
                    st.error("Naive Bayes modeli yÃ¼klenemedi. LÃ¼tfen Ã¶nce modeli eÄŸitin.")
            else:
                st.warning("LÃ¼tfen bir haber baÅŸlÄ±ÄŸÄ± girin.")
    
    # Lojistik Regresyon sÃ¼tunu
    with col2:
        if st.button("Lojistik Regresyon ile Tahmin Et"):
            if user_input:
                # Lojistik Regresyon modelini yÃ¼kler
                tfidf_vectorizer, lr_model = load_tfidf_lr_model()
                
                if tfidf_vectorizer is not None and lr_model is not None:
                    # Tahmin iÅŸlemini gerÃ§ekleÅŸtirir
                    prediction, probability = predict_with_lr(user_input, tfidf_vectorizer, lr_model)
                    
                    # SonuÃ§larÄ± kullanÄ±cÄ±ya gÃ¶sterir
                    st.success(f"Tahmin: **{prediction}**")
                    st.info(f"GÃ¼ven: {probability:.2f}%")
                else:
                    st.error("Lojistik Regresyon modeli yÃ¼klenemedi. LÃ¼tfen Ã¶nce modeli eÄŸitin.")
            else:
                st.warning("LÃ¼tfen bir haber baÅŸlÄ±ÄŸÄ± girin.")
    
    # BERT sÃ¼tunu
    with col3:
        if st.button("BERT ile Tahmin Et"):
            if user_input:
                # BERT modelini yÃ¼kler
                tokenizer, model, label_classes, device = load_bert_model()
                
                if tokenizer is not None and model is not None and label_classes is not None:
                    # BERT ile tahmin iÅŸlemini gerÃ§ekleÅŸtirir
                    prediction, probability = predict_with_bert(user_input, tokenizer, model, label_classes, device)
                    
                    # SonuÃ§larÄ± kullanÄ±cÄ±ya gÃ¶sterir
                    st.success(f"Tahmin: **{prediction}**")
                    st.info(f"GÃ¼ven: {probability:.2f}%")
                else:
                    st.error("BERT modeli yÃ¼klenemedi. LÃ¼tfen Ã¶nce modeli eÄŸitin.")
            else:
                st.warning("LÃ¼tfen bir haber baÅŸlÄ±ÄŸÄ± girin.")
    
    # Ã–rnek haber baÅŸlÄ±klarÄ±nÄ± kullanÄ±cÄ±ya sunar
    st.subheader("Ã–rnek Haber BaÅŸlÄ±klarÄ±")
    st.markdown("""
    1. "TÃ¼rkiyenin ekonomik bÃ¼yÃ¼mesi beklentilerin Ã¼zerinde gerÃ§ekleÅŸti"
    2. "Galatasaray deplasmanda FenerbahÃ§eyi 2-1 maÄŸlup etti"
    3. "SaÄŸlÄ±k BakanlÄ±ÄŸÄ± yeni Covid-19 HastalÄ±ÄŸÄ± tedbirlerini aÃ§Ä±kladÄ±"
    4. "CumhurbaÅŸkanÄ± yeni kabineyi aÃ§Ä±kladÄ±"
    5. "Bilim insanlarÄ± yeni bir gezegen keÅŸfetti"
    """)

# Veri Seti sekmesi iÃ§eriÄŸi
with tab2:
    st.header("Veri Seti GÃ¶rselleri")
    
    try:
        # Kategori daÄŸÄ±lÄ±mÄ± grafiÄŸini gÃ¶sterir
        st.subheader("Kategori DaÄŸÄ±lÄ±mÄ±")
        if os.path.exists("kategori_dagilimi.png"):
            st.image("kategori_dagilimi.png", caption="Haber Kategorilerinin DaÄŸÄ±lÄ±mÄ±")
        else:
            # EÄŸer dosya yoksa, veri iÃ§i bir grafik oluÅŸturur
            category_counts = pd.Series({
                "Ekonomi": 5,
                "Magazin": 5,
                "SaÄŸlÄ±k": 5,
                "Siyaset": 5,
                "Spor": 5,
                "Teknoloji": 5,
                "YaÅŸam": 5
            })
            fig, ax = plt.subplots(figsize=(10, 6))
            sns.barplot(x=category_counts.values, y=category_counts.index, ax=ax)
            ax.set_title('Haber Kategorilerinin DaÄŸÄ±lÄ±mÄ±')
            ax.set_xlabel('Haber SayÄ±sÄ±')
            ax.set_ylabel('Kategoriler')
            st.pyplot(fig)
        
        # Kelime sayÄ±sÄ± daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶sterir
        st.subheader("Kelime SayÄ±sÄ± DaÄŸÄ±lÄ±mÄ±")
        if os.path.exists("kelime_sayisi_dagilimi.png"):
            st.image("kelime_sayisi_dagilimi.png", caption="Haberlerdeki Kelime SayÄ±sÄ± DaÄŸÄ±lÄ±mÄ±")
        
        # Kategori-kelime sayÄ±sÄ± iliÅŸkisini gÃ¶rselleÅŸtirir
        st.subheader("Kategori-Kelime SayÄ±sÄ± Ä°liÅŸkisi")
        if os.path.exists("kategori_kelime_sayisi.png"):
            st.image("kategori_kelime_sayisi.png", caption="Kategorilere GÃ¶re Ortalama Kelime SayÄ±larÄ±")
        
        # BERT eÄŸitim metriklerini gÃ¶sterir
        st.subheader("BERT EÄŸitim Metrikleri")
        if os.path.exists("bert_training_history.png"):
            st.image("bert_training_history.png", caption="BERT Modelinin EÄŸitim SÃ¼recindeki Metrikler")
        
        # BERT karÄ±ÅŸÄ±klÄ±k matrisini gÃ¶rselleÅŸtirir
        st.subheader("BERT KarÄ±ÅŸÄ±klÄ±k Matrisi")
        if os.path.exists("bert_confusion_matrix.png"):
            st.image("bert_confusion_matrix.png", caption="BERT Modelinin KarÄ±ÅŸÄ±klÄ±k Matrisi")
        
        # AÅŸÄ±rÄ± Ã¶ÄŸrenme analizini gÃ¶sterir
        st.subheader("AÅŸÄ±rÄ± Ã–ÄŸrenme (Overfitting) Analizi")
        if os.path.exists("bert_overfitting_analysis.png"):
            st.image("bert_overfitting_analysis.png", caption="BERT Modelinin AÅŸÄ±rÄ± Ã–ÄŸrenme Analizi")
        
        # Klasik modellerin karÄ±ÅŸÄ±klÄ±k matrisini gÃ¶rselleÅŸtirir
        st.subheader("Klasik Modellerin KarÄ±ÅŸÄ±klÄ±k Matrisi")
        if os.path.exists("confusion_matrix.png"):
            st.image("confusion_matrix.png", caption="Klasik Modellerin KarÄ±ÅŸÄ±klÄ±k Matrisi")
            
    except Exception as e:
        st.error(f"GÃ¶rsel yÃ¼kleme hatasÄ±: {e}")
        st.info("GÃ¶rseller yÃ¼klenirken bir hata oluÅŸtu. LÃ¼tfen 'Tahmin' sekmesine geÃ§erek modeli kullanÄ±n.")

# HakkÄ±nda sekmesi iÃ§eriÄŸi
with tab3:
    st.header("Proje HakkÄ±nda")
    
    st.markdown("""
    ## TÃ¼rkÃ§e Haber BaÅŸlÄ±klarÄ±nÄ± SÄ±nÄ±flandÄ±rma Projesi
    
    Bu proje, TÃ¼rkÃ§e haber baÅŸlÄ±klarÄ±nÄ± kategorilerine gÃ¶re sÄ±nÄ±flandÄ±rmak iÃ§in kullanÄ±lan yapay zeka modellerini iÃ§ermektedir.
    
    ### KullanÄ±lan Modeller
    
    1. **Geleneksel Makine Ã–ÄŸrenmesi Modelleri**:
       - Naive Bayes: OlasÄ±lÄ±k tabanlÄ± sÄ±nÄ±flandÄ±rma algoritmasÄ±
       - Lojistik Regresyon: DoÄŸrusal model tabanlÄ± sÄ±nÄ±flandÄ±rma yÃ¶ntemi
    
    2. **Derin Ã–ÄŸrenme Modeli**:
       - BERT (Bidirectional Encoder Representations from Transformers): Son teknoloji NLP modeli
    ```bash
    !.. NOT: BERT modeli yeterli veri seti olmadÄ±ÄŸÄ± iÃ§in bazÄ± durumlar Overfitting olabilir..!
    ```
        
    
    ### KullanÄ±lan Teknolojiler
    
    - Python: Ana programlama dili
    - Pandas, NumPy: Veri manipÃ¼lasyonu ve analizi
    - Scikit-Learn: Geleneksel makine Ã¶ÄŸrenmesi algoritmalarÄ±
    - PyTorch: Derin Ã¶ÄŸrenme framework'Ã¼
    - Transformers (Hugging Face): BERT modeli implementasyonu
    - NLTK: DoÄŸal dil iÅŸleme kÃ¼tÃ¼phanesi
    - Streamlit: Web arayÃ¼zÃ¼ oluÅŸturma
    """)
    
    st.sidebar.title("Model Bilgileri")
    st.sidebar.markdown("""
    **Geleneksel Modeller**:
    - TF-IDF vektÃ¶rleÅŸtirme: Metinleri sayÄ±sal Ã¶zelliklere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r
    - Naive Bayes: Bayes teoremi tabanlÄ± sÄ±nÄ±flandÄ±rÄ±cÄ±
    - Lojistik Regresyon: DoÄŸrusal sÄ±nÄ±flandÄ±rÄ±cÄ±
    
    **Derin Ã–ÄŸrenme**:
    - BERT (TÃ¼rkÃ§e model): Ã‡ift yÃ¶nlÃ¼ transformers mimarisi
    """)
    
    # Model durumunu kontrol eder ve bilgi verir
    st.sidebar.title("Model Durumu")
    
    # NB model durumunu kontrol eder
    if os.path.exists('tfidf_vectorizer.pkl') and os.path.exists('nb_model.pkl'):
        st.sidebar.success("âœ… Naive Bayes modeli yÃ¼klÃ¼")
    else:
        st.sidebar.error("âŒ Naive Bayes modeli yÃ¼klÃ¼ deÄŸil")
    
    # LR model durumunu kontrol eder
    if os.path.exists('tfidf_vectorizer.pkl') and os.path.exists('lr_model.pkl'):
        st.sidebar.success("âœ… Lojistik Regresyon modeli yÃ¼klÃ¼")
    else:
        st.sidebar.error("âŒ Lojistik Regresyon modeli yÃ¼klÃ¼ deÄŸil")
    
    # BERT model durumunu kontrol eder
    if os.path.exists('bert_haber_siniflandirici.pth') and os.path.exists('model_siniflar.txt'):
        st.sidebar.success("âœ… BERT modeli yÃ¼klÃ¼")
    else:
        st.sidebar.error("âŒ BERT modeli yÃ¼klÃ¼ deÄŸil") 