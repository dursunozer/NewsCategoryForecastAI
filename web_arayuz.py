import streamlit as st
import pandas as pd
import torch
import matplotlib.pyplot as plt
import seaborn as sns
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
import pickle
import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import joblib
import os

# NLTK'nin gerekli verileri indirme
try:
    nltk.data.find('tokenizers/punkt')
    nltk.data.find('corpora/stopwords')
except LookupError:
    print("NLTK veri paketleri indiriliyor...")
    nltk.download('punkt')
    nltk.download('stopwords')
    print("Ä°ndirme tamamlandÄ±.")

# TÃ¼rkÃ§e stopwords
try:
    tr_stop_words = set(stopwords.words('turkish'))
except LookupError:
    print("TÃ¼rkÃ§e stopwords indiriliyor...")
    nltk.download('stopwords')
    tr_stop_words = set(stopwords.words('turkish'))

# Sayfa baÅŸlÄ±ÄŸÄ±
st.set_page_config(page_title="Haber Kategori Tahmini", page_icon="ğŸ“°", layout="wide")
st.title("Haber Kategori Tahmini")
st.markdown("Bu uygulama, haber baÅŸlÄ±klarÄ±nÄ± kategorilerine gÃ¶re sÄ±nÄ±flandÄ±rÄ±r.")

# Metin temizleme iÅŸlemleri
def metin_temizle(text):
    """Metni temizleme: Ã¶zel karakterleri kaldÄ±rma ve kÃ¼Ã§Ã¼k harfe Ã§evirme"""
    if isinstance(text, str):
        # KÃ¼Ã§Ã¼k harfe Ã§evirme
        text = text.lower()
        # Noktalama iÅŸaretlerini kaldÄ±rma
        text = re.sub(r'[^\w\s]', '', text)
        # Gereksiz boÅŸluklarÄ± kaldÄ±rma
        text = re.sub(r'\s+', ' ', text).strip()
        return text
    return ""

# Durak kelimeleri kaldÄ±rma
def durak_kelimeleri_kaldir(text):
    """TÃ¼rkÃ§e durak kelimelerini metinden Ã§Ä±karma"""
    if isinstance(text, str):
        tokens = word_tokenize(text)
        filtered_tokens = [word for word in tokens if word not in tr_stop_words]
        return ' '.join(filtered_tokens)
    return ""

# BERT iÃ§in metin temizleme
def bert_metin_temizle(text):
    """Metni temizleme: Ã¶zel karakterleri kaldÄ±rma ve dÃ¼zenleme"""
    if isinstance(text, str):
        # Gereksiz karakterleri kaldÄ±rma
        text = re.sub(r'[^\w\s.?!,]', '', text)
        # Gereksiz boÅŸluklarÄ± kaldÄ±rma
        text = re.sub(r'\s+', ' ', text).strip()
        return text
    return ""

# Modelleri yÃ¼kleme fonksiyonlarÄ±
@st.cache_resource
def load_tfidf_nb_model():
    """TF-IDF ve Naive Bayes modellerini yÃ¼kleme"""
    try:
        # Model ve vektÃ¶rleÅŸtirici dosyalarÄ±nÄ± kontrol et
        if os.path.exists('tfidf_vectorizer.pkl') and os.path.exists('nb_model.pkl'):
            with open('tfidf_vectorizer.pkl', 'rb') as f:
                tfidf_vectorizer = pickle.load(f)
            with open('nb_model.pkl', 'rb') as f:
                nb_model = pickle.load(f)
            return tfidf_vectorizer, nb_model
        else:
            st.warning("TF-IDF ve Naive Bayes model dosyalarÄ± bulunamadÄ±. Ã–nce modelleri eÄŸitmelisiniz.")
            return None, None
    except Exception as e:
        st.error(f"Model yÃ¼kleme hatasÄ±: {e}")
        return None, None

@st.cache_resource
def load_tfidf_lr_model():
    """TF-IDF ve Lojistik Regresyon modellerini yÃ¼kleme"""
    try:
        # Model ve vektÃ¶rleÅŸtirici dosyalarÄ±nÄ± kontrol et
        if os.path.exists('tfidf_vectorizer.pkl') and os.path.exists('lr_model.pkl'):
            with open('tfidf_vectorizer.pkl', 'rb') as f:
                tfidf_vectorizer = pickle.load(f)
            with open('lr_model.pkl', 'rb') as f:
                lr_model = pickle.load(f)
            return tfidf_vectorizer, lr_model
        else:
            st.warning("TF-IDF ve Lojistik Regresyon model dosyalarÄ± bulunamadÄ±. Ã–nce modelleri eÄŸitmelisiniz.")
            return None, None
    except Exception as e:
        st.error(f"Model yÃ¼kleme hatasÄ±: {e}")
        return None, None

@st.cache_resource
def load_bert_model():
    """BERT modelini yÃ¼kleme"""
    try:
        # BERT model dosyasÄ±nÄ± kontrol et
        if os.path.exists('bert_haber_siniflandirici.pth') and os.path.exists('model_siniflar.txt'):
            # SÄ±nÄ±flarÄ± yÃ¼kle
            label_classes = []
            with open('model_siniflar.txt', 'r', encoding='utf-8') as f:
                for line in f:
                    parts = line.strip().split(': ')
                    if len(parts) == 2:
                        label_classes.append(parts[1])
            
            # CihazÄ± belirle
            device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            
            # Tokenizer yÃ¼kle
            tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-turkish-cased")
            
            # Model yÃ¼kle
            model = AutoModelForSequenceClassification.from_pretrained(
                "dbmdz/bert-base-turkish-cased",
                num_labels=len(label_classes)
            )
            
            # EÄŸitilmiÅŸ model aÄŸÄ±rlÄ±klarÄ±nÄ± yÃ¼kle
            model.load_state_dict(torch.load('bert_haber_siniflandirici.pth', map_location=device))
            model.to(device)
            model.eval()
            
            return tokenizer, model, label_classes, device
        else:
            st.warning("BERT model dosyalarÄ± bulunamadÄ±. Ã–nce modeli eÄŸitmelisiniz.")
            return None, None, None, None
    except Exception as e:
        st.error(f"BERT model yÃ¼kleme hatasÄ±: {e}")
        return None, None, None, None

# Tahmin fonksiyonlarÄ±
def predict_with_nb(text, vectorizer, model):
    """Naive Bayes ile tahmin et"""
    if vectorizer is None or model is None:
        return "Model yÃ¼klenemedi. LÃ¼tfen Ã¶nce modeli eÄŸitin."
    
    # Metin Ã¶niÅŸleme
    clean_text = metin_temizle(text)
    processed_text = durak_kelimeleri_kaldir(clean_text)
    
    # VektÃ¶rleÅŸtirme ve tahmin
    text_vector = vectorizer.transform([processed_text])
    prediction = model.predict(text_vector)[0]
    
    # OlasÄ±lÄ±klarÄ± al
    probs = model.predict_proba(text_vector)[0]
    max_prob = max(probs) * 100
    
    return prediction, max_prob

def predict_with_lr(text, vectorizer, model):
    """Lojistik Regresyon ile tahmin et"""
    if vectorizer is None or model is None:
        return "Model yÃ¼klenemedi. LÃ¼tfen Ã¶nce modeli eÄŸitin."
    
    # Metin Ã¶niÅŸleme
    clean_text = metin_temizle(text)
    processed_text = durak_kelimeleri_kaldir(clean_text)
    
    # VektÃ¶rleÅŸtirme ve tahmin
    text_vector = vectorizer.transform([processed_text])
    prediction = model.predict(text_vector)[0]
    
    # OlasÄ±lÄ±klarÄ± al
    probs = model.predict_proba(text_vector)[0]
    max_prob = max(probs) * 100
    
    return prediction, max_prob

def predict_with_bert(text, tokenizer, model, label_classes, device):
    """BERT ile tahmin et"""
    if tokenizer is None or model is None or label_classes is None:
        return "BERT model yÃ¼klenemedi. LÃ¼tfen Ã¶nce modeli eÄŸitin."
    
    # Metin Ã¶niÅŸleme
    clean_text = bert_metin_temizle(text)
    
    # TokenleÅŸtirme
    encoding = tokenizer(
        clean_text,
        add_special_tokens=True,
        max_length=128,
        truncation=True,
        padding='max_length',
        return_tensors='pt'
    )
    
    # TensÃ¶rleri cihaza taÅŸÄ±
    input_ids = encoding['input_ids'].to(device)
    attention_mask = encoding['attention_mask'].to(device)
    
    # Tahmin
    with torch.no_grad():
        outputs = model(input_ids=input_ids, attention_mask=attention_mask)
        logits = outputs.logits
        probs = torch.nn.functional.softmax(logits, dim=1)
        max_prob, preds = torch.max(probs, dim=1)
    
    # Tahmin edilen sÄ±nÄ±fÄ± ve olasÄ±lÄ±ÄŸÄ± dÃ¶ndÃ¼r
    predicted_class = label_classes[preds.item()]
    probability = max_prob.item() * 100
    
    return predicted_class, probability

# Ana sayfa
tab1, tab2, tab3 = st.tabs(["Tahmin", "Veri Seti", "HakkÄ±nda"])

with tab1:
    st.header("Haber BaÅŸlÄ±ÄŸÄ± Tahmin Et")
    
    # KullanÄ±cÄ± giriÅŸi
    user_input = st.text_area("Haber baÅŸlÄ±ÄŸÄ± girin:", height=100)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("Naive Bayes ile Tahmin Et"):
            if user_input:
                # Modelleri yÃ¼kle
                tfidf_vectorizer, nb_model = load_tfidf_nb_model()
                
                if tfidf_vectorizer is not None and nb_model is not None:
                    # Tahmin yap
                    prediction, probability = predict_with_nb(user_input, tfidf_vectorizer, nb_model)
                    
                    # SonuÃ§larÄ± gÃ¶ster
                    st.success(f"Tahmin: **{prediction}**")
                    st.info(f"GÃ¼ven: {probability:.2f}%")
                else:
                    st.error("Naive Bayes modeli yÃ¼klenemedi. LÃ¼tfen Ã¶nce modeli eÄŸitin.")
            else:
                st.warning("LÃ¼tfen bir haber baÅŸlÄ±ÄŸÄ± girin.")
    
    with col2:
        if st.button("Lojistik Regresyon ile Tahmin Et"):
            if user_input:
                # Modelleri yÃ¼kle
                tfidf_vectorizer, lr_model = load_tfidf_lr_model()
                
                if tfidf_vectorizer is not None and lr_model is not None:
                    # Tahmin yap
                    prediction, probability = predict_with_lr(user_input, tfidf_vectorizer, lr_model)
                    
                    # SonuÃ§larÄ± gÃ¶ster
                    st.success(f"Tahmin: **{prediction}**")
                    st.info(f"GÃ¼ven: {probability:.2f}%")
                else:
                    st.error("Lojistik Regresyon modeli yÃ¼klenemedi. LÃ¼tfen Ã¶nce modeli eÄŸitin.")
            else:
                st.warning("LÃ¼tfen bir haber baÅŸlÄ±ÄŸÄ± girin.")
    
    with col3:
        if st.button("BERT ile Tahmin Et"):
            if user_input:
                # BERT modelini yÃ¼kle
                tokenizer, model, label_classes, device = load_bert_model()
                
                if tokenizer is not None and model is not None and label_classes is not None:
                    # Tahmin yap
                    prediction, probability = predict_with_bert(user_input, tokenizer, model, label_classes, device)
                    
                    # SonuÃ§larÄ± gÃ¶ster
                    st.success(f"Tahmin: **{prediction}**")
                    st.info(f"GÃ¼ven: {probability:.2f}%")
                else:
                    st.error("BERT modeli yÃ¼klenemedi. LÃ¼tfen Ã¶nce modeli eÄŸitin.")
            else:
                st.warning("LÃ¼tfen bir haber baÅŸlÄ±ÄŸÄ± girin.")
    
    # Ã–rnek haber baÅŸlÄ±klarÄ±
    st.subheader("Ã–rnek Haber BaÅŸlÄ±klarÄ±")
    st.markdown("""
    1. "TÃ¼rkiyenin ekonomik bÃ¼yÃ¼mesi beklentilerin Ã¼zerinde gerÃ§ekleÅŸti"
    2. "Galatasaray deplasmanda FenerbahÃ§eyi 2-1 maÄŸlup etti"
    3. "SaÄŸlÄ±k BakanlÄ±ÄŸÄ± yeni Covid-19 HastalÄ±ÄŸÄ± tedbirlerini aÃ§Ä±kladÄ±"
    4. "CumhurbaÅŸkanÄ± yeni kabineyi aÃ§Ä±kladÄ±"
    5. "Bilim insanlarÄ± yeni bir gezegen keÅŸfetti"
    """)

with tab2:
    st.header("Veri Seti")
    
    try:
        # Veri setini yÃ¼kle ve gÃ¶ster
        if os.path.exists('veri/TurkishHeadlines.csv'):
            df = pd.read_csv('veri/TurkishHeadlines.csv')
            
            # Veri seti bilgileri
            st.subheader("Veri Seti Ã–zeti")
            st.write(f"Toplam kayÄ±t sayÄ±sÄ±: {df.shape[0]}")
            
            # Kategorileri gÃ¶ster
            st.subheader("Kategori DaÄŸÄ±lÄ±mÄ±")
            category_counts = df['ETIKET'].value_counts()
            
            # Grafik oluÅŸtur
            fig, ax = plt.subplots(figsize=(10, 6))
            sns.barplot(x=category_counts.values, y=category_counts.index, ax=ax)
            ax.set_title('Haber Kategorilerinin DaÄŸÄ±lÄ±mÄ±')
            ax.set_xlabel('Haber SayÄ±sÄ±')
            ax.set_ylabel('Kategoriler')
            st.pyplot(fig)
            
            # Ã–rnek verileri gÃ¶ster
            st.subheader("Kategorilere GÃ¶re Haberler")
            
            # Her kategoriden 5'er tane Ã¶rnek seÃ§me
            for kategori in sorted(df['ETIKET'].unique()):
                with st.expander(f"{kategori} Kategorisi Haberleri", expanded=True):
                    kategori_df = df[df['ETIKET'] == kategori].head(5)
                    for _, row in kategori_df.iterrows():
                        st.write(f"**{row['HABERLER']}**")
        else:
            st.warning("Veri seti bulunamadÄ±. LÃ¼tfen 'veri/TurkishHeadlines.csv' dosyasÄ±nÄ±n mevcut olduÄŸundan emin olun.")
    except Exception as e:
        st.error(f"Veri yÃ¼kleme hatasÄ±: {e}")

with tab3:
    st.header("Proje HakkÄ±nda")
    
    st.markdown("""
    ## TÃ¼rkÃ§e Haber BaÅŸlÄ±klarÄ±nÄ± SÄ±nÄ±flandÄ±rma Projesi
    
    Bu proje, TÃ¼rkÃ§e haber baÅŸlÄ±klarÄ±nÄ± kategorilerine gÃ¶re sÄ±nÄ±flandÄ±rmak iÃ§in kullanÄ±lan yapay zeka modellerini iÃ§ermektedir.
    
    ### KullanÄ±lan Modeller
    
    1. **Geleneksel Makine Ã–ÄŸrenmesi Modelleri**:
       - Naive Bayes
       - Lojistik Regresyon
    
    2. **Derin Ã–ÄŸrenme Modeli**:
       - BERT (Bidirectional Encoder Representations from Transformers)
    ```bash
    !.. NOT: BERT modeli yeterli veri seti olmadÄ±ÄŸÄ± iÃ§in bazÄ± durumlar Overfitting olabilir..!
    ```
        
    
    ### KullanÄ±lan Teknolojiler
    
    - Python
    - Pandas, NumPy
    - Scikit-Learn
    - PyTorch
    - Transformers (Hugging Face)
    - NLTK
    - Streamlit
    """)
    
    st.sidebar.title("Model Bilgileri")
    st.sidebar.markdown("""
    **Geleneksel Modeller**:
    - TF-IDF vektÃ¶rleÅŸtirme
    - Naive Bayes
    - Lojistik Regresyon
    
    **Derin Ã–ÄŸrenme**:
    - BERT (TÃ¼rkÃ§e model)
    """)
    
    # Model durumunu kontrol et
    st.sidebar.title("Model Durumu")
    
    # NB model durumu
    if os.path.exists('tfidf_vectorizer.pkl') and os.path.exists('nb_model.pkl'):
        st.sidebar.success("âœ… Naive Bayes modeli yÃ¼klÃ¼")
    else:
        st.sidebar.error("âŒ Naive Bayes modeli yÃ¼klÃ¼ deÄŸil")
    
    # LR model durumu
    if os.path.exists('tfidf_vectorizer.pkl') and os.path.exists('lr_model.pkl'):
        st.sidebar.success("âœ… Lojistik Regresyon modeli yÃ¼klÃ¼")
    else:
        st.sidebar.error("âŒ Lojistik Regresyon modeli yÃ¼klÃ¼ deÄŸil")
    
    # BERT model durumu
    if os.path.exists('bert_haber_siniflandirici.pth') and os.path.exists('model_siniflar.txt'):
        st.sidebar.success("âœ… BERT modeli yÃ¼klÃ¼")
    else:
        st.sidebar.error("âŒ BERT modeli yÃ¼klÃ¼ deÄŸil") 